{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUFuoiXrehY6"
      },
      "source": [
        "Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsmaNxnWeDEE"
      },
      "source": [
        "import time\n",
        "import warnings\n",
        "#warnings.filterwarnings('ignore')\n",
        "from mnist import MNIST #this is for loading input data\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR0G-gxjeVui"
      },
      "source": [
        "emnist = MNIST('/content/mnist_data')\n",
        "emnist.select_emnist('balanced')\n",
        "\n",
        "images,labels = emnist.load_training()\n",
        "testIM,testLAB = emnist.load_testing()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7moSV57ebTc"
      },
      "source": [
        "n_images = np.array(images)\n",
        "n_labels = np.array(labels)\n",
        "testIM = np.array(testIM)\n",
        "testLAB = np.array(testLAB)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDSIdZQHeoUQ"
      },
      "source": [
        "visualizing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zh1azkV2ecMa"
      },
      "source": [
        "n_images1 = n_images[19000].reshape(28,28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3B-kmjcecrL"
      },
      "source": [
        "plt.imshow(n_images1,cmap='gist_gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7i3A5CUe2i0"
      },
      "source": [
        "Normailizing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zgzGz8Tecs6"
      },
      "source": [
        "n_images[0][455]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDdGtDG1ecu_"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(n_images)\n",
        "train_images = scaler.transform(n_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JU8njqdecyp"
      },
      "source": [
        "train_images[0][455]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ish8T8sKfC1B"
      },
      "source": [
        "scaler.fit(testIM)\n",
        "test_images = scaler.transform(testIM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngDVyOHifE5R"
      },
      "source": [
        "testIM[0][567]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2iaqsZzfFCv"
      },
      "source": [
        "test_images[0][567]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESd8ONL-fJV7"
      },
      "source": [
        "Adding new dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6DfTAwofIli"
      },
      "source": [
        "from PIL import ImageFilter,Image\n",
        "import helper"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLKoTi7LfIm2"
      },
      "source": [
        "count=47\n",
        "for k in range(1,15):\n",
        "    for i in range(1,50):\n",
        "        try:\n",
        "            im = Image.open('Addeddataset/a{}- ({}).jpg'.format(k,i)).convert('LA')\n",
        "            print(\"done\")\n",
        "        except:\n",
        "            print(\"error\")\n",
        "            break\n",
        "        n_image = helper.normalize_to_emnist(im)\n",
        "        train_images = np.append(train_images,[n_image],axis=0)\n",
        "        test_images = np.append(test_images,[n_image],axis=0)\n",
        "        n_labels = np.append(n_labels,[count])\n",
        "        testLAB = np.append(testLAB,[count])\n",
        "    count+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-rNgYCufIou"
      },
      "source": [
        "print(len(train_images))\n",
        "print(len(test_images))\n",
        "print(len(n_labels))\n",
        "print(len(testLAB))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMVTEuoDfIsb"
      },
      "source": [
        "%store n_images\n",
        "%store n_labels\n",
        "%store testIM \n",
        "%store testLAB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6gttNMtfVan"
      },
      "source": [
        "n_labels[113015]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-WKBSILfVfL"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl3tO00qfViB"
      },
      "source": [
        "n_labels[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utY9tFhffncb"
      },
      "source": [
        "shaped_n_labels  = n_labels.reshape(-1,1)\n",
        "enc = OneHotEncoder()\n",
        "enc.fit(shaped_n_labels)\n",
        "train_labels = enc.transform(shaped_n_labels).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba1VQcvbfnol"
      },
      "source": [
        "train_labels[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VckFz3Gvfnre"
      },
      "source": [
        "shaped_testLAB = testLAB.reshape(-1,1)\n",
        "enc.fit(shaped_testLAB)\n",
        "test_labels = enc.transform(shaped_testLAB).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOFNY18kfzec"
      },
      "source": [
        "def init_weights(shape):\n",
        "    init_random_dist = tf.truncated_normal(shape,stddev=0.1)\n",
        "    return tf.Variable(init_random_dist)\n",
        "# initialising bias\n",
        "def init_bias(shape):\n",
        "    init_bias_vals = tf.constant(0.1,shape=shape)\n",
        "    return tf.Variable(init_bias_vals)\n",
        "#conv2d\n",
        "def conv2d(x,W):\n",
        "    #x -> [bias,height,width,channels]\n",
        "    #W -> [Filter H,filter W,Channel In,Channel Out]\n",
        "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')\n",
        "#pooling layer\n",
        "def max_pool_2by2(x):\n",
        "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
        "#Convolutional layer\n",
        "def convolutional_layer(input_x,shape):\n",
        "    W=init_weights(shape)\n",
        "    bias = init_bias([shape[3]])\n",
        "    return tf.nn.relu(conv2d(input_x,W)+bias)\n",
        "#Fully connected layer\n",
        "def normal_full_layer(input_layer,size):\n",
        "    input_size = int(input_layer.get_shape()[1])\n",
        "    W = init_weights([input_size,size])\n",
        "    bias = init_bias([size])\n",
        "    return tf.matmul(input_layer,W) + bias"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37VdHWQtf37p"
      },
      "source": [
        "Creating model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfEU7rp1fzhU"
      },
      "source": [
        "x = tf.placeholder(tf.float32,shape=[None,784])\n",
        "y_true=tf.placeholder(tf.float32,shape=[None,59])\n",
        "\n",
        "#layers(input)\n",
        "x_image = tf.reshape(x,[-1,28,28,1])\n",
        "\n",
        "#first convolutional layer\n",
        "convo_1 = convolutional_layer(x_image,shape=[5,5,1,32])\n",
        "convo_1_pooling = max_pool_2by2(convo_1)\n",
        "\n",
        "#second convolutional layer\n",
        "convo_2 = convolutional_layer(convo_1_pooling,shape=[5,5,32,64])\n",
        "convo_2_pooling = max_pool_2by2(convo_2)\n",
        "\n",
        "#fully connected layer\n",
        "convo_flat = tf.reshape(convo_2_pooling,[-1,7*7*64])\n",
        "full_layer_one = tf.nn.relu(normal_full_layer(convo_flat,1024))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj8GK42_f-zE"
      },
      "source": [
        "optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPm3Kk6lfzon"
      },
      "source": [
        "#drop out (used to overcome overfitting)\n",
        "\n",
        "hold_prob = tf.placeholder(tf.float32)\n",
        "full_one_dropout = tf.nn.dropout(full_layer_one,keep_prob=hold_prob)\n",
        "\n",
        "y_pred = normal_full_layer(full_one_dropout,59)\n",
        "\n",
        "#Loss Function \n",
        "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true,logits = y_pred))\n",
        "\n",
        "#optimizer\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate = 0.001)\n",
        "train =optimizer.minimize(cross_entropy)\n",
        "\n",
        "#initialise variables to execute it\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "steps = 5000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lhJl8x5fzro"
      },
      "source": [
        "saver = tf.train.Saver()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVQWtxBOgGcC"
      },
      "source": [
        "Training and saving the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gI0bajUTgDFT"
      },
      "source": [
        "start = time.time()\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    batch_size = 120\n",
        "    for i in range(steps):\n",
        "        rand_ind = np.random.randint(len(train_images),size=batch_size)\n",
        "        feed = {x:train_images[rand_ind],y_true:train_labels[rand_ind],hold_prob:0.5}\n",
        "        sess.run(train,feed_dict=feed)\n",
        "        \n",
        "        if i%100 == 0:\n",
        "            print(\"On step: {}\".format(i))\n",
        "            match = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
        "            acc = tf.reduce_mean(tf.cast(match,tf.float32))\n",
        "            print(\"Accuracy obtained at {x} is {y}\".format(x=i,y=sess.run(acc,feed_dict={x:test_images,y_true:test_labels,hold_prob:1.0})))\n",
        "            print('\\n')\n",
        "    saver.save(sess,'model/cnn_model_1_with_tamil.ckpt')\n",
        "end = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeDR3KfIo5a4"
      },
      "source": [
        "Predicting the input image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a__EPoEbgDIQ"
      },
      "source": [
        "from sklearn.metrics import log_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L8nMtfFgMJs"
      },
      "source": [
        "%store -r n_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrepPdOogMRu"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "        sess.run(init)\n",
        "        saver.restore(sess, \"model/cnn_model_1_with_tamil.ckpt\")\n",
        "       \n",
        "        prediction=tf.argmax(y_pred,1)\n",
        "        var = prediction.eval(feed_dict={x: [n_image],y_true:train_labels,hold_prob: 0.5}, session=sess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_EYnQ5GgsVy"
      },
      "source": [
        "labels_dict ={0:0,1:1,2:2,3:3,4:4,5:5,6:6,7:7,8:8,9:9,10:'A',11:'B',12:'C',13:'D',14:'E',15:'F',16:'G',17:'H',18:'I',19:'J',20:'K',21:'l',22:'M',23:'N',24:'O',25:'P',26:'Q',27:'R',28:'S',29:'T',30:'u',31:'V',32:'W',33:'X',34:'Y',35:'Z',36:'a',37:'b',38:'d',39:'e',40:'f',41:'g',42:'h',43:'n',44:'q',45:'r',46:'t',47:'அ',48:'ஆ'}\n",
        "labels_dict[49]=\"இ\"\n",
        "labels_dict[50]='ஈ'\n",
        "labels_dict[51]='உ'\n",
        "labels_dict[52]='ஊ'\n",
        "labels_dict[53]='எ'\n",
        "labels_dict[54]='ஏ'\n",
        "labels_dict[55]='ஐ'\n",
        "labels_dict[56]='ஒ'\n",
        "labels_dict[57]='ஓ'\n",
        "labels_dict[58]='ஔ'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKJ2r_kzgsxW"
      },
      "source": [
        "print('The predicted character is : \"{}\"'.format(labels_dict[var[0]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBVML8-pg1IT"
      },
      "source": [
        "n_images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQrv5SOcg1Sy"
      },
      "source": [
        "%store -r n_images\n",
        "%store -r n_labels\n",
        "%store -r testIM \n",
        "%store -r testLAB"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}